# Markdown Chat (mdchat) âœ¨  
Collaborate with LLMs directly in your terminal.  
Ask, edit, summarize, and generate content inline in Markdown.  

---

## ğŸš€ Features
- ğŸ“ **Ask questions** and insert AI answers directly into `.md` files.  
- âœï¸ **Edit sections** with AI-powered rewrites (simplify, clarify, shorten, etc.).  
- ğŸ“š **Summarize** long notes or papers into concise takeaways.  
- ğŸ“„ **Generate blog posts** and documentation in Markdown.  
- ğŸ’¬ **Interactive chat mode** with an LLM inside your terminal.  

All AI-generated content is wrapped in `<!-- AI: ... -->` blocks, so you always know whatâ€™s machine-written.  

---

## ğŸ“¦ Installation
```bash
# install globally
npm install -g mdchat

# or run once via npx
npx mdchat --help


**Requirements:** Node.js 20+
```
## ğŸ¯ Commands

### Ask Question

```bash
# Ask a question (streaming by default for better UX)
mdchat ask "What is the capital of France?"

# Disable streaming if you prefer to see the complete response at once
mdchat ask "Explain quantum computing" --no-stream

# Save the answer to a file
mdchat ask "How does photosynthesis work?" -o biology.md
```

### Summarize Content
```bash
# Summarize a single file
mdchat summarize document.md

# Summarize multiple files with glob patterns
mdchat summarize "docs/*.md"

# Summarize an entire directory
mdchat summarize ./research/

# Save summary to a file
mdchat summarize notes.md -o summary.md
```

### Edit Content  
```bash
# Simplify a section
mdchat edit document.md --section "Complex Topic" --action simplify

# Expand on a topic
mdchat edit article.md --section "Introduction" --action expand

# Clarify technical content
mdchat edit guide.md --section "Setup" --action clarify
```

### Configuration
As of now, it does not work. By default, only openai model is used (and gpt-4o at that!)
```bash
# Set your preferred AI provider and model
mdchat config --provider openai --model gpt-4
mdchat config --api-key your-api-key

# Use different providers
mdchat config --provider anthropic --model claude-3-sonnet
```

---

## âš™ï¸ Global Options
- `--provider <provider>`: AI provider (openai, anthropic, etc.)
- `--model <model>`: Model to use (gpt-4, claude-3-sonnet, etc.)
- `--api-key <key>`: API key for the provider
- `--base-url <url>`: Custom API base URL

---

## ğŸ¨ Examples

Ask a question (streaming by default):
```bash
mdchat ask "Write a comprehensive guide to Node.js best practices"
```

Summarize multiple research papers:
```bash
mdchat summarize "research/papers/*.md" -o research-summary.md
```

Edit and improve a blog post:
```bash
mdchat edit blog-post.md --section "Conclusion" --action expand
```

---

## ğŸ”§ Environment Setup

Set your API key as an environment variable:
```bash
export OPENAI_API_KEY="your-api-key-here"
# or  
export ANTHROPIC_API_KEY="your-anthropic-key"
```

Or configure it via the CLI:
```bash
mdchat config --api-key your-api-key
```

---

## ğŸ“ Output Format

All AI responses are wrapped in HTML comments for easy identification:

<!-- AI:answer -->
Your AI-generated content appears here.
<!-- /AI -->

This makes it clear what content was generated by AI vs. human-written.
